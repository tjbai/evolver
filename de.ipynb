{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sanity check overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from de import DependencyEvolver\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = DependencyEvolver(\n",
    "    d_model=16,\n",
    "    dim_feedforward=8,\n",
    "    nhead=1,\n",
    "    dropout=0,\n",
    "    N=5,\n",
    "    encoder_layers=1,\n",
    "    decoder_layers=1,\n",
    "    tok_v=tokenizer.vocab_size,\n",
    "    rel_v=2,\n",
    "    pos_v=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "\n",
    "batch = (\n",
    "    (8823, 2),\n",
    "    [\n",
    "        torch.tensor([[[1, 0, 2, 0, 3]]]),\n",
    "        torch.tensor([[[-1, -1, 1, -1, -1]]]),\n",
    "        torch.tensor([[[-1, 2, -1, 2, -1]]]),\n",
    "        torch.tensor([[[-1, 0, -1, 1, -1]]]),\n",
    "        torch.tensor([[[-1, 0, -1, 1, -1]]]),\n",
    "        torch.tensor([[[-1, 2016, -1, 2833, -1]]])\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_loader = [batch for _ in range(1000)]\n",
    "eval_loader = [batch for _ in range(20)]\n",
    "optim = AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._train(optim, train_loader, eval_loader, len(train_loader), 20, 1, 1e9, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full data creation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "\n",
    "with open('./data/ud/en_gum-ud-dev.conllu', 'r') as f:\n",
    "    sentences = conllu.parse(f.read())\n",
    "\n",
    "parsed = sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_tree(parsed):\n",
    "    children = {tok['id']: [] for tok in parsed}\n",
    "    for tok in parsed:\n",
    "        if tok['head'] != 0: children[tok['head']].append(tok['id'])\n",
    "        \n",
    "    i, root = next((i, tok) for (i, tok) in enumerate(parsed) if tok['head'] == 0)\n",
    "\n",
    "    seqs = [[(root['form'], root['upos'], root['deprel'], i, True, -1)]]\n",
    "    cur_leaves = [root['id']]\n",
    "    all_leaves = [root['id']]\n",
    "\n",
    "    while cur_leaves:\n",
    "        seq = []\n",
    "        next_leaves = []\n",
    "        \n",
    "        for i, tok in enumerate(parsed):\n",
    "            if tok['id'] in all_leaves or tok['head'] in all_leaves:\n",
    "                seq.append((\n",
    "                    tok['form'], tok['upos'], tok['deprel'],\n",
    "                    i, tok['head'] in cur_leaves, None\n",
    "                ))\n",
    "                if tok['head'] in cur_leaves: next_leaves.extend(children[tok['id']])\n",
    "                \n",
    "        for i, (form, upos, deprel, j, is_leaf, _) in enumerate(seq):\n",
    "            tok = next(t for t in parsed if t['form'] == form and t['upos'] == upos and t['deprel'] == deprel)\n",
    "            if tok['head'] == 0:\n",
    "                par = -1\n",
    "            else:\n",
    "                par = next((j for j, (p_form, p_upos, p_deprel, _, _, _) in enumerate(seq)\n",
    "                            if p_form == parsed[tok['head']-1]['form']\n",
    "                            and p_upos == parsed[tok['head']-1]['upos']\n",
    "                            and p_deprel == parsed[tok['head']-1]['deprel']),\n",
    "                            None)\n",
    "            \n",
    "            seq[i] = (form, upos, deprel, j, is_leaf, par)\n",
    "        \n",
    "        seqs.append(seq)\n",
    "        cur_leaves = next_leaves\n",
    "        all_leaves.extend(next_leaves)\n",
    "        \n",
    "    return seqs\n",
    "\n",
    "seqs = family_tree(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "\n",
    "for i in range(len(seqs)-1):\n",
    "    a, b = seqs[i], seqs[i+1]\n",
    "    new_pos = []\n",
    "    prev = {i: is_leaf for (_, _, _, i, is_leaf, _) in a}\n",
    "   \n",
    "    op_list = [] \n",
    "    cpy_list = []\n",
    "    par_list = []\n",
    "    tok_list = []\n",
    "    pos_list = []\n",
    "    rel_list = []\n",
    "    \n",
    "    for i, (tok, pos, rel, j, _, par) in enumerate(b):\n",
    "        if j in prev:\n",
    "            op_list.append(2 if prev[j] else 1)\n",
    "            cpy_list.append(next(i for i, t in enumerate(a) if t[3] == j))\n",
    "            par_list.append(-1)\n",
    "            tok_list.append(-1)\n",
    "            rel_list.append(-1)\n",
    "            pos_list.append(-1)\n",
    "        else:\n",
    "            op_list.append(0)\n",
    "            cpy_list.append(-1)\n",
    "            par_list.append(par)\n",
    "            \n",
    "            # TODO -- tokenizer for this stuff\n",
    "            tok_list.append(None)\n",
    "            rel_list.append(None)\n",
    "            pos_list.append(None)\n",
    "            \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Research', 'has', -1, 'insight', '1', '.']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
