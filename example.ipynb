{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simalign import SentenceAligner\n",
    "aligner = SentenceAligner(model='bert', token_type='bpe', matching_methods='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import generate_edits, to_str\n",
    "\n",
    "a = 'Jo was great at the Best Western.'\n",
    "b = 'At the Best Western, the hotel manager Jo was really good.'\n",
    "\n",
    "a_toks = tokenizer.tokenize(a)\n",
    "for edit in generate_edits(a, b, tokenizer, aligner):\n",
    "    print(to_str(*edit, a_toks, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forced Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import EvolverDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trajectory_list = []\n",
    "for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "    trajectory = []\n",
    "    for i in range(4):\n",
    "        trajectory.append(' '.join([letter for _ in range(2**i)]))\n",
    "    trajectory_list.append(trajectory)\n",
    "    \n",
    "dataset = EvolverDataset(trajectory_list, max_len=10, force_targets=True, name='toy')\n",
    "loader = DataLoader(dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import elaborate\n",
    "input_ids, traj_edit_tgts = next(iter(loader))\n",
    "elaborate(traj_edit_tgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import train_forced\n",
    "from model import Evolver\n",
    "from torch.optim import AdamW\n",
    "\n",
    "evolver = Evolver(d_model=512, max_len=10, include_sub=False)\n",
    "optim = AdamW(evolver.parameters(), lr=1e-3)\n",
    "\n",
    "train_forced(evolver, optim, loader, 10, 10, None, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Evolver\n",
    "\n",
    "evolver = Evolver(nhead=8)\n",
    "\n",
    "s1 = 'a b c d'\n",
    "s2 = 'b c d a'\n",
    "\n",
    "s1 = tokenizer(s1, return_tensors='pt', max_length=10, padding='max_length')['input_ids'].squeeze()\n",
    "s2 = tokenizer(s2, return_tensors='pt', max_length=10, padding='max_length')['input_ids'].squeeze()\n",
    "\n",
    "src, src_pad_mask = evolver.get_src(s1)\n",
    "_, tgt_pad_mask = evolver.get_src(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import particle_filter\n",
    "\n",
    "evolver.eval()\n",
    "\n",
    "res, *_ = particle_filter(\n",
    "    evolver, s1, s2,\n",
    "    src, src_pad_mask, tgt_pad_mask,\n",
    "    5, 2, 1.0, device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import elaborate\n",
    "elaborate(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import TrainLoader\n",
    "\n",
    "traj_list = []\n",
    "for c in 'abcd':\n",
    "    traj = []\n",
    "    for i in range(4):\n",
    "        traj.append(' '.join([c for _ in range(2**i)]))\n",
    "    traj_list.append(traj) \n",
    "\n",
    "train_loader = TrainLoader(traj_list, bsz=1, max_len=10, tokenizer=tokenizer).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import EvalLoader, get_input_ids\n",
    "\n",
    "traj_list = [' '.join([c for _ in range(8)]) for c in 'wxyz']\n",
    "\n",
    "eval_loader = EvalLoader(traj_list, num_samples=3, max_len=10, tokenizer=tokenizer).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Evolver\n",
    "from train import train_evolver\n",
    "from torch.optim import AdamW\n",
    "\n",
    "evolver = Evolver(encoder_layers=3, decoder_layers=3, device='cpu')\n",
    "optim = AdamW(evolver.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evolver(\n",
    "    evolver, optim, train_loader, eval_loader,\n",
    "    epochs=25, checkpoint_at=50, eval_at=1,\n",
    "    num_particles=10, threshold=0, temperature=1,\n",
    "    prefix='test-3-larger', device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from run import sample_trajectory\n",
    "\n",
    "evolver.eval()\n",
    "\n",
    "rand = Evolver(encoder_layers=1, decoder_layers=1)\n",
    "rand.eval()\n",
    "\n",
    "traj_input_ids = eval_loader.traj_input_ids[0]\n",
    "\n",
    "print(sample_trajectory(\n",
    "    evolver, traj_input_ids,\n",
    "    1, 0, 1, device='cpu'\n",
    ")[1])\n",
    "\n",
    "print(sample_trajectory(\n",
    "    rand, traj_input_ids,\n",
    "    1, 0, 1, device='cpu'\n",
    ")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data import Seq2SeqDataset, StratifiedInfiniteSampler\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "dataset = Seq2SeqDataset(\n",
    "    inputs=['hello', 'hello my', 'hello my name', 'hello my name is'],\n",
    "    outputs=['hello my', 'hello my name', 'hello my name is', 'hello my name is TJ'],\n",
    "    max_len=10,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=4, sampler=StratifiedInfiniteSampler(dataset, 4))\n",
    "eval_loader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Transformer\n",
    "from torch.optim import AdamW\n",
    "from constants import VOCAB_SIZE\n",
    "\n",
    "model = Transformer(\n",
    "    d_model=512,\n",
    "    nhead=2,\n",
    "    max_len=10,\n",
    "    dropout=0.1,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    encoder_layers=2,\n",
    "    decoder_layers=2\n",
    ")\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_ar\n",
    "\n",
    "train_ar(\n",
    "    model, optim, None,\n",
    "    train_loader, eval_loader,\n",
    "    100, 1, 2000, 20,\n",
    "    'cpu', 'toy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --config=configs/ud-2.0.0.json --device=cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batched Particle Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import TrajectoryDataset, StratifiedInfiniteSampler, collate_unsupervised\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "traj_list = []\n",
    "for c in 'abcd':\n",
    "    traj = ['']\n",
    "    for i in range(4):\n",
    "        traj.append(' '.join([c for _ in range(2**i)]))\n",
    "    traj_list.append(traj) \n",
    "    \n",
    "dataset = TrajectoryDataset(\n",
    "    traj_list=traj_list,\n",
    "    log_probs=[0 for _ in range(2)],\n",
    "    max_len=10, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=collate_unsupervised,\n",
    "    sampler=StratifiedInfiniteSampler(dataset, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/toy/toy.jsonl', 'w') as f:\n",
    "    for thing in traj_list:\n",
    "        json.dump((thing, 0), f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Evolver\n",
    "from torch.optim import AdamW\n",
    "\n",
    "evolver = Evolver(\n",
    "    d_model=128,\n",
    "    nhead=2,\n",
    "    max_len=10,\n",
    "    encoder_layers=4,\n",
    "    decoder_layers=4,\n",
    "    dropout=0,\n",
    "    dim_feedforward=512\n",
    ")\n",
    "\n",
    "optim = AdamW(evolver.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_evolver\n",
    "\n",
    "train_evolver(\n",
    "    evolver, optim, None, train_loader, train_loader,\n",
    "    train_steps=100, eval_steps=1, grad_accum_steps=1, checkpoint_at=200, eval_at=10,\n",
    "    num_particles=5, threshold=3, temperature=1, resample_at=1,\n",
    "    device='cpu', prefix='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised (Best-of-1) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Evolver\n",
    "from torch.optim import AdamW\n",
    "\n",
    "evolver = Evolver(\n",
    "    d_model=128,\n",
    "    nhead=2,\n",
    "    max_len=10,\n",
    "    encoder_layers=4,\n",
    "    decoder_layers=4,\n",
    "    dropout=0,\n",
    "    dim_feedforward=512\n",
    ")\n",
    "\n",
    "optim = AdamW(evolver.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import TrajectoryDataset, SupervisedTrajectoryDataset, StratifiedInfiniteSampler\n",
    "from torch.utils.data import DataLoader\n",
    "    \n",
    "dataset = SupervisedTrajectoryDataset(\n",
    "    traj_list=[['', 'a', 'a a a'], ['', 'b', 'b b', 'b b b b b', 'b b b b b b b b']],\n",
    "    log_probs=[0 for _ in range(2)],\n",
    "    max_len=10, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "eval_dataset = TrajectoryDataset(\n",
    "    traj_list=[['', 'a', 'a a a'], ['', 'b', 'b b', 'b b b b b', 'b b b b b b b b']],\n",
    "    log_probs=[0 for _ in range(2)],\n",
    "    max_len=10, tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import collate_supervised, collate_unsupervised\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=collate_supervised,\n",
    "    sampler=StratifiedInfiniteSampler(dataset, 2)\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=1,\n",
    "    collate_fn=collate_unsupervised,\n",
    "    # sampler=StratifiedInfiniteSampler(eval_dataset, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_evolver\n",
    "\n",
    "train_evolver(\n",
    "    evolver, optim, None, train_loader, eval_loader,\n",
    "    train_steps=100, eval_steps=1, grad_accum_steps=1, checkpoint_at=200, eval_at=10,\n",
    "    num_particles=5, threshold=3, temperature=1, resample_at=1,\n",
    "    device='cpu', name='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import Evolver\n",
    "from data import get_input_ids\n",
    "\n",
    "model = Evolver(max_len=64)\n",
    "model.load_state_dict(torch.load('checkpoints/sup-ud-3.0.pt', map_location='cpu')['model'])\n",
    "model.eval()\n",
    "\n",
    "inputs = ['hello', 'hello my', 'hello my name is']\n",
    "input_ids = get_input_ids(inputs, 64, tokenizer)\n",
    "\n",
    "src, src_pad_mask = model.get_src(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import fast_sample\n",
    "\n",
    "edit_tgts, log_probs = fast_sample(model, input_ids, src, src_pad_mask, 3, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import elaborate\n",
    "\n",
    "elaborate(edit_tgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vals = torch.exp(probs[1][2].squeeze())\n",
    "sup_vals = torch.exp(sup_probs[1][2].squeeze())\n",
    "\n",
    "val, idxs = torch.topk(vals, k=5)\n",
    "sup_val, sup_idxs = torch.topk(sup_vals, k=5)\n",
    "\n",
    "fig, axs = plt.subplots(2)\n",
    "\n",
    "axs[0].plot(torch.arange(VOCAB_SIZE).detach(), vals.detach())\n",
    "axs[1].plot(torch.arange(VOCAB_SIZE).detach(), sup_vals.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## playground"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omniglot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
