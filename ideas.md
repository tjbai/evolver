# different directions to pursue...

## focus: deep embeddings

is this a focus or just something we can tack-on as a side effect?

angle around reasoning tasks that require generating a CoT--delimit reasoning chains by complete phrases

## focus: edit-based generation

teach a model, possibly pretrained, how to defer generation and correct generations from previous steps

centered around posisble imitation learning/reinforcement learning methods

could possibly be pretrained in some form without deeper embeddings and then finetuned later on

## focus: diffusion-language models

pretrain on noised-up dependency trees to predict constituents

