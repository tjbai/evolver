{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evo import *\n",
    "\n",
    "params = {\n",
    "    'd_model': 512,\n",
    "    'nhead': 8,\n",
    "    'dim_feedforward': 2048,\n",
    "    'dropout': 0.1,\n",
    "    'encoder_layers': 3,\n",
    "    'decoder_layers': 3,\n",
    "    'max_len': 64\n",
    "}\n",
    "\n",
    "evolver = Evolver(**params)\n",
    "ps_evolver = PointerStyleEvolver(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_loader = supervised_loader(\n",
    "    path='data/ud/ud_train_3.0.jsonl',\n",
    "    max_len=10,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=4,\n",
    "    cache_prefix=None,\n",
    "    all_tokens=True,\n",
    "    limit=20,\n",
    "    sampler=StratifiedInfiniteSampler\n",
    ")\n",
    "\n",
    "eval_loader = unsupervised_loader(\n",
    "    path='data/toy/toy.jsonl',\n",
    "    max_len=10,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=4,\n",
    "    sampler=StratifiedInfiniteSampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import apply_edits\n",
    "\n",
    "traj_input_ids, _, traj_edit_tgts, _ = next(iter(train_loader))\n",
    "\n",
    "apply_edits(traj_input_ids[:, 0], tuple(map(lambda x: x[:, 0], traj_edit_tgts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "kwargs = {\n",
    "    'train_loader': train_loader,\n",
    "    'eval_loader': eval_loader,\n",
    "    'train_steps': 1,\n",
    "    'eval_steps': 2,\n",
    "    'grad_accum_steps': 1,\n",
    "    'clip_gradients': False,\n",
    "    'checkpoint_at': 20,\n",
    "    'eval_at': 1\n",
    "}\n",
    "\n",
    "print('STARTING REGULAR EVOLVER')\n",
    "train_evolver(evolver, AdamW(evolver.parameters(), lr=3e-4), None, **kwargs)\n",
    "\n",
    "print('STARTING PS EVOLVER')\n",
    "train_evolver(ps_evolver, AdamW(ps_evolver.parameters(), lr=3e-4), None, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multihead pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from trans import MultiheadPointer\n",
    "\n",
    "pointer = MultiheadPointer(512, 8)\n",
    "\n",
    "mem = torch.randn(3, 10, 512)\n",
    "tgt = torch.randn(3, 5, 512)\n",
    "src_pad_mask = torch.full((3, 10), True)\n",
    "src_pad_mask[:, :7] = False\n",
    "\n",
    "idx_weights = pointer(tgt, mem, key_padding_mask=src_pad_mask)\n",
    "idx_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regressions\n",
    "\n",
    "```\n",
    "python evo.py --config=configs/toy/sup-toy.json\n",
    "python evo.py --config=configs/toy/sup-toy-epoch.json\n",
    "python evo.py --config=configs/toy/ps-sup-toy.json\n",
    "!python evo.py --config=configs/toy/ps-unsup-toy.json\n",
    "python evo.py --config=configs/toy/noshare-sup-toy-e1d1.json\n",
    "python evo.py --config=configs/toy/den-toy.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evo.py --config=configs/toy/sup-toy.json --local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evo.py --config=configs/toy/sup-toy-epoch.json --local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evo.py --config=configs/toy/ps-unsup-toy.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evo.py --config=configs/toy/ps-sup-toy.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evo.py --config=configs/toy/den-toy.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:train:using <class 'data.StratifiedInfiniteSampler'> in loader\n",
      "INFO:train:using ar loaders\n",
      "INFO:data:tokenizing sequence dataset...\n",
      "INFO:data:done in 0.00 seconds!\n",
      "tokenizing trajectories: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 2262.60it/s]\n",
      "INFO:train:starting run for 500 steps\n",
      "INFO:train:eval every 20 steps\n",
      "INFO:train:checkpoint every 500 steps\n",
      "INFO:train:using <class '__main__.Transformer'>\n",
      "INFO:train:starting new run\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtjbai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/bai/argo/projects/ddm/evolver/wandb/run-20240821_221147-j1dborig\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mar-d-toy_20240821_221146\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/tjbai/evolver\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/tjbai/evolver/runs/j1dborig\u001b[0m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:17<00:00, 27.89it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.006 MB of 0.014 MB uploaded (0.002 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/loss ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/time ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñá‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñÇ‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/loss -1.72153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/time 0.22525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mar-d-toy_20240821_221146\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/tjbai/evolver/runs/j1dborig\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/tjbai/evolver\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240821_221147-j1dborig/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
     ]
    }
   ],
   "source": [
    "!python evo.py --config=configs/toy/ar-d-toy.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import unsupervised_loader, StratifiedInfiniteSampler\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "loader = unsupervised_loader(\n",
    "    'data/toy/toy.jsonl',\n",
    "    max_len=10,\n",
    "    tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "    batch_size=2,\n",
    "    sampler=StratifiedInfiniteSampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    print(batch[0].shape)\n",
    "    traj_input_ids = batch[0]\n",
    "    break\n",
    "\n",
    "input_ids = traj_input_ids[:, 0]\n",
    "output_ids = traj_input_ids[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, N = input_ids.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
