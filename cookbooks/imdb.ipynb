{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def noise(seq):\n",
    "    toks = tokenizer(seq, max_length=512, truncation=True)['input_ids'][1:-1]\n",
    "    traj = [tokenizer.decode(toks)]\n",
    "    N = len(toks)\n",
    "    \n",
    "    while toks:\n",
    "        toks = toks[:len(toks)//2]\n",
    "        traj.append(tokenizer.decode(toks))\n",
    "        \n",
    "    return traj[::-1], 0, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "lengths = []\n",
    "\n",
    "with open('../data/imdb/imdb_train_3.jsonl', 'w') as train_f, open('../data/imdb/imdb_dev_3.jsonl', 'w') as dev_f:\n",
    "    for i, file in tqdm(enumerate(os.listdir('../data/imdb/raw/train/neg'))):\n",
    "        df = train_f if i < 10000 else dev_f\n",
    "        with open(f'../data/imdb/raw/train/neg/{file}', 'r') as f:\n",
    "            seq = f.read()\n",
    "            *traj, N = noise(seq)\n",
    "            json.dump(traj, df)\n",
    "            df.write('\\n')\n",
    "            lengths.append(N)\n",
    "            \n",
    "    for i, file in tqdm(enumerate(os.listdir('../data/imdb/raw/train/pos'))):\n",
    "        df = train_f if i < 10000 else dev_f\n",
    "        with open(f'../data/imdb/raw/train/pos/{file}', 'r') as f:\n",
    "            seq = f.read()\n",
    "            *traj, N = noise(seq)\n",
    "            json.dump(traj, df)\n",
    "            df.write('\\n')\n",
    "            lengths.append(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from transformers import BertTokenizer\n",
    "from constants import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "with open('../data/imdb/imdb_train_3.jsonl', 'r') as f:\n",
    "    for i, line in tqdm(enumerate(f.readlines())):\n",
    "        if not line: continue\n",
    "        traj, _ = json.loads(line)\n",
    "        ids = torch.tensor(traj)\n",
    "        \n",
    "        traj_op_tgts = []\n",
    "        traj_tok_tgts = []\n",
    "        traj_idx_tgts = []\n",
    "        \n",
    "        for j, seq in enumerate(ids[1:], start=1):\n",
    "            N = len(ids[j-1]) - 2\n",
    "            M = len(seq) - 2 - N\n",
    "            \n",
    "            op_tgts = [INS_ID] + [CPY_ID for _ in range(N)] + [INS_ID for _ in range(M)] + [EOS_ID]\n",
    "            tok_tgts = [BOS_TOKEN_ID] + [PAD_TOKEN_ID for _ in range(N)] + [tok for tok in seq[1+N:1+N+M]] + [PAD_TOKEN_ID]\n",
    "            idx_tgts = [0]  + [i for i in range(1, N+1)] + [0 for _ in range(M)] + [0]\n",
    "           \n",
    "            # pad out to 512 \n",
    "            op_tgts += [PAD_ID for _ in range(512-len(seq))]\n",
    "            tok_tgts += [PAD_TOKEN_ID for _ in range(512-len(seq))]\n",
    "            idx_tgts += [0 for _ in range(512-len(seq))]\n",
    "            \n",
    "            traj_op_tgts.append(op_tgts)\n",
    "            traj_tok_tgts.append(tok_tgts)\n",
    "            traj_idx_tgts.append(idx_tgts)\n",
    "            \n",
    "        traj_op_tgts = torch.tensor(traj_op_tgts)\n",
    "        traj_tok_tgts = torch.tensor(traj_tok_tgts)\n",
    "        traj_idx_tgts = torch.tensor(traj_idx_tgts)\n",
    "        \n",
    "        with open(f'../data/imdb/cache_3/sup-imdb-3_{i}.zst', 'wb') as f:\n",
    "            pickle.dump((traj_op_tgts, traj_tok_tgts, traj_idx_tgts), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import elaborate\n",
    "import torch.nn.functional as F\n",
    "\n",
    "with open('../data/imdb/imdb_train_2.jsonl', 'r') as f:\n",
    "    for i, line in tqdm(enumerate(f.readlines())):\n",
    "        if not line: continue\n",
    "        traj, _ = json.loads(line)\n",
    "        ids = torch.tensor(traj)\n",
    "        \n",
    "        traj_op_tgts = []\n",
    "        traj_tok_tgts = []\n",
    "        traj_idx_tgts = []\n",
    "        \n",
    "        for j, seq in enumerate(ids[1:], start=1):\n",
    "            N = len(ids[j-1]) \n",
    "            assert N == len(seq)\n",
    "            \n",
    "            op_tgts = [PAD_ID for _ in range(512)]\n",
    "            tok_tgts = [PAD_TOKEN_ID for _ in range(512)]\n",
    "            idx_tgts = [0 for _ in range(512)]\n",
    "            \n",
    "            op_tgts[0] = INS_ID\n",
    "            tok_tgts[0] = BOS_TOKEN_ID\n",
    "            \n",
    "            op_tgts[N-1] = EOS_ID\n",
    "            \n",
    "            for k, (a, b) in enumerate(zip(ids[j-1][1:-1], seq[1:-1]), start=1):\n",
    "                if a == b:\n",
    "                    op_tgts[k] = CPY_ID\n",
    "                    idx_tgts[k] = k\n",
    "                \n",
    "                else:\n",
    "                    assert a.item() == 103\n",
    "                    op_tgts[k] = SUB_ID\n",
    "                    tok_tgts[k] = b.item()\n",
    "                    idx_tgts[k] = k\n",
    "                    \n",
    "            traj_op_tgts.append(op_tgts)\n",
    "            traj_tok_tgts.append(tok_tgts)\n",
    "            traj_idx_tgts.append(idx_tgts)\n",
    "            \n",
    "        traj_op_tgts = torch.tensor(traj_op_tgts)\n",
    "        traj_tok_tgts = torch.tensor(traj_tok_tgts)\n",
    "        traj_idx_tgts = torch.tensor(traj_idx_tgts)\n",
    "        \n",
    "        with open(f'../data/imdb/cache_2/sup-imdb-2_{i}.zst', 'wb') as f:\n",
    "            pickle.dump((traj_op_tgts, traj_tok_tgts, traj_idx_tgts), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "traj_op_tgts = F.one_hot(traj_op_tgts, 5)\n",
    "traj_tok_tgts = F.one_hot(traj_tok_tgts, VOCAB_SIZE)\n",
    "traj_idx_tgts = F.one_hot(traj_idx_tgts, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import elaborate\n",
    "\n",
    "elaborate((traj_op_tgts, traj_tok_tgts, traj_idx_tgts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspection\n",
    "\n",
    "sup-imdb-1.3: fixed loss composition and achieves best eval out of this batch of experiments, but the index head plateaus and op loss isn't great\n",
    "\n",
    "sup-imbd-1.4: added scaling to index and op heads, which resulted in much lower loss, but eval is significaly worse\n",
    "\n",
    "what gives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import Evolver\n",
    "from data import get_input_ids\n",
    "\n",
    "model_13 = Evolver(d_model=512, max_len=512)\n",
    "model_13.load_state_dict(torch.load('../checkpoints/sup-imdb-1.3.pt', map_location='cpu')['model'])\n",
    "model_13.eval()\n",
    "\n",
    "model_14 = Evolver(d_model=512, max_len=512)\n",
    "model_14.load_state_dict(torch.load('../checkpoints/sup-imdb-1.4.pt', map_location='cpu')['model'])\n",
    "model_14.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['very unnecessary movie with']\n",
    "traj_input_ids = get_input_ids(inputs, 512, tokenizer)\n",
    "\n",
    "tokenizer('very unnecessary movie with characters that are acting so')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from constants import *\n",
    "from data import get_edit_tgts\n",
    "\n",
    "edit_tgts = get_edit_tgts(\n",
    "    [\n",
    "        (INS_ID, BOS_TOKEN_ID, 0),\n",
    "        (CPY_ID, PAD_TOKEN_ID, 1),\n",
    "        (CPY_ID, PAD_TOKEN_ID, 2),\n",
    "        (CPY_ID, PAD_TOKEN_ID, 3),\n",
    "        (CPY_ID, PAD_TOKEN_ID, 4),\n",
    "        (INS_ID, 3494, 0),\n",
    "        (INS_ID, 2008, 0),\n",
    "        (INS_ID, 2024, 0),\n",
    "        (INS_ID, 3772, 0),\n",
    "        (INS_ID, 2061, 0),\n",
    "    ],\n",
    "    max_len=512\n",
    ")\n",
    "\n",
    "op_tgts = F.one_hot(torch.tensor(edit_tgts[0]), 5).unsqueeze(0)\n",
    "tok_tgts = F.one_hot(torch.tensor(edit_tgts[1]), VOCAB_SIZE).unsqueeze(0)\n",
    "idx_tgts = F.one_hot(torch.tensor(edit_tgts[2]), 512).unsqueeze(0)\n",
    "\n",
    "from data import elaborate\n",
    "elaborate((op_tgts, tok_tgts, idx_tgts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_14.train()\n",
    "src, src_pad_mask = model_14.get_src(traj_input_ids)\n",
    "probs_14, tgt, _, _ = model_14.forward(traj_input_ids, src, (op_tgts, tok_tgts, idx_tgts), src_pad_mask, None, None, None)\n",
    "\n",
    "model_13.train()\n",
    "src, src_pad_mask = model_13.get_src(traj_input_ids)\n",
    "probs_13, tgt, _, _ = model_13.forward(traj_input_ids, src, (op_tgts, tok_tgts, idx_tgts), src_pad_mask, None, None, None)\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# a, b, c = [], [], []\n",
    "# memory = cache = None\n",
    "# src, src_pad_mask = model_14.get_src(traj_input_ids)\n",
    "\n",
    "# for i in tqdm(range(1, 6)):\n",
    "#     edit_tgts = tuple(map(\n",
    "#         lambda x: x[:, :i],\n",
    "#         (op_tgts, tok_tgts, idx_tgts)\n",
    "#     ))\n",
    "    \n",
    "#     probs, tgt, memory, cache = model_14.forward(traj_input_ids, src, edit_tgts, src_pad_mask, None, memory, cache)\n",
    "#     op_probs, tok_probs, idx_probs = tuple(map(lambda x: x[:, -1].squeeze().detach(), probs))\n",
    "    \n",
    "#     print('best token', torch.argmax(tok_probs))\n",
    "#     print('best index', torch.argmax(idx_probs))\n",
    "       \n",
    "#     a.append(torch.exp(op_probs).numpy())\n",
    "#     b.append(torch.exp(tok_probs).numpy())\n",
    "#     c.append(torch.exp(idx_probs).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_printoptions(threshold=float('inf'))\n",
    "\n",
    "print((probs_14[0][:, :10]))\n",
    "print((probs_13[0][:, :10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(5, 10))\n",
    "\n",
    "im1 = ax1.imshow(np.array(a).T, aspect='auto', cmap='plasma')\n",
    "plt.colorbar(im1, ax=ax1)\n",
    "\n",
    "im2 = ax2.imshow(np.array(b).T, aspect='auto', cmap='plasma')\n",
    "plt.colorbar(im2, ax=ax2)\n",
    "\n",
    "im3 = ax3.imshow(np.array(c).T, aspect='auto', cmap='plasma')\n",
    "plt.colorbar(im3, ax=ax3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import TrajectoryDataset\n",
    "\n",
    "dataset = TrajectoryDataset.from_disk(\n",
    "    '../data/imdb/imdb_dev_1.jsonl',\n",
    "    max_len=512,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from train import evolver_elbo\n",
    "from data import collate_unsupervised\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=1, collate_fn=collate_unsupervised)\n",
    "\n",
    "loss = evolver_elbo(model_13, loader, 1, 'cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
