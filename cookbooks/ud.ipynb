{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "\n",
    "with open('../data/ud/en_ewt-ud-train.conllu', 'r') as f:\n",
    "    sentences = conllu.parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 12544/12544 [00:04<00:00, 2549.80it/s]\n",
      "generated 12544 noising trajectories\n",
      "avg length 5.66047512755102\n"
     ]
    }
   ],
   "source": [
    "!python ../dep.py ../data/en_ewt-ud-train.conllu ../data/ud.jsonl --weight=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "with open('../data/ud/en_ewt-ud-dev.conllu', 'r') as f:\n",
    "    sentences = conllu.parse(f.read())\n",
    "    \n",
    "detok = TreebankWordDetokenizer()\n",
    "\n",
    "sentences = [detok.detokenize([t['form'] for t in sent]) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ud/dev.txt', 'w') as f:\n",
    "    for sent in sentences:\n",
    "        f.write(sent)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tok = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "ids = tok(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([895., 532., 295., 155.,  66.,  35.,  11.,   6.,   4.,   2.]),\n",
       " array([ 3. , 12.3, 21.6, 30.9, 40.2, 49.5, 58.8, 68.1, 77.4, 86.7, 96. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGdCAYAAAAIbpn/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfBklEQVR4nO3df2zU9eHH8Vd/0FKgd7V1vaOzlc6RQAUVKZQDsy2jsWh1Y3ZumEqqEpnYKj8Ubadg1GERN3WgwjQOSIQxScQfdeKa4qrMUkoBxy8LiziqeK2u6x2gtNB7f/9Y+MQTvpODluPdPh/JJ7Gfz/vu3nfvhT736d3nYowxRgAAABaKjfYEAAAAzhQhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBa8dGewJkIhUI6ePCgkpOTFRMTE+3pAACA02CM0aFDh5SRkaHY2O45l2JlyBw8eFCZmZnRngYAADgDzc3Nuuiii7rlvqwMmeTkZEn/fSFcLleUZwMAAE5HMBhUZmam83u8O1gZMif+nORyuQgZAAAs051vC+HNvgAAwFqEDAAAsBYhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBahAwAALAWIQMAAKxFyAAAAGsRMgAAwFqEDAAAsFZ8tCdwPhpS/ma0pxCxjxcWRnsKAACcc5yRAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANYiZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANYiZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFgropDp6urSvHnzlJ2draSkJF1yySV69NFHZYxxxhhjNH/+fA0ePFhJSUnKz8/Xvn37wu6nra1NxcXFcrlcSklJ0bRp03T48OHueUYAAKDPiChkHn/8cS1dulTPPPOM9uzZo8cff1yLFi3SkiVLnDGLFi3S4sWLtWzZMtXX12vgwIEqKCjQ0aNHnTHFxcXatWuXqqurVVVVpXfffVfTp0/vvmcFAAD6hBjz9dMp3+K6666Tx+PRiy++6OwrKipSUlKSXnrpJRljlJGRoXvuuUf33nuvJCkQCMjj8WjFihWaMmWK9uzZo5ycHDU0NCg3N1eStH79el177bX65JNPlJGR8a3zCAaDcrvdCgQCcrlckT7nbzWk/M1uv8+e9vHCwmhPAQCA/6knfn9HdEZm/Pjxqqmp0d69eyVJH3zwgTZu3KhrrrlGkrR//375/X7l5+c7t3G73crLy1NdXZ0kqa6uTikpKU7ESFJ+fr5iY2NVX19/1k8IAAD0HfGRDC4vL1cwGNSwYcMUFxenrq4uLViwQMXFxZIkv98vSfJ4PGG383g8zjG/36/09PTwScTHKzU11RnzTR0dHero6HB+DgaDkUwbAAD0UhGdkXn55Ze1atUqrV69Wlu3btXKlSv129/+VitXruyp+UmSKisr5Xa7nS0zM7NHHw8AANghopCZO3euysvLNWXKFI0cOVJTp07V7NmzVVlZKUnyer2SpJaWlrDbtbS0OMe8Xq9aW1vDjh8/flxtbW3OmG+qqKhQIBBwtubm5kimDQAAeqmIQubLL79UbGz4TeLi4hQKhSRJ2dnZ8nq9qqmpcY4Hg0HV19fL5/NJknw+n9rb29XY2OiM2bBhg0KhkPLy8k75uImJiXK5XGEbAABARO+Ruf7667VgwQJlZWXp0ksv1bZt2/Tkk0/qtttukyTFxMRo1qxZ+s1vfqOhQ4cqOztb8+bNU0ZGhiZPnixJGj58uCZNmqTbb79dy5Yt07Fjx1RWVqYpU6ac1ieWAAAATogoZJYsWaJ58+bpzjvvVGtrqzIyMvSrX/1K8+fPd8bcd999OnLkiKZPn6729nZdddVVWr9+vfr37++MWbVqlcrKyjRx4kTFxsaqqKhIixcv7r5nBQAA+oSIriNzvuA6MifjOjIAgPNd1K8jAwAAcD4hZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANYiZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANYiZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANYiZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANYiZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANYiZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYK+KQ+fTTT3XzzTcrLS1NSUlJGjlypLZs2eIcN8Zo/vz5Gjx4sJKSkpSfn699+/aF3UdbW5uKi4vlcrmUkpKiadOm6fDhw2f/bAAAQJ8SUcj85z//0YQJE9SvXz+99dZb2r17t373u9/pggsucMYsWrRIixcv1rJly1RfX6+BAweqoKBAR48edcYUFxdr165dqq6uVlVVld59911Nnz69+54VAADoE2KMMeZ0B5eXl+vvf/+73nvvvVMeN8YoIyND99xzj+69915JUiAQkMfj0YoVKzRlyhTt2bNHOTk5amhoUG5uriRp/fr1uvbaa/XJJ58oIyPjW+cRDAbldrsVCATkcrlOd/qnbUj5m91+nz3t44WF0Z4CAAD/U0/8/o7ojMzrr7+u3Nxc3XjjjUpPT9eoUaP0wgsvOMf3798vv9+v/Px8Z5/b7VZeXp7q6uokSXV1dUpJSXEiRpLy8/MVGxur+vr6Uz5uR0eHgsFg2AYAABBRyHz00UdaunSphg4dqrffflszZszQ3XffrZUrV0qS/H6/JMnj8YTdzuPxOMf8fr/S09PDjsfHxys1NdUZ802VlZVyu93OlpmZGcm0AQBALxVRyIRCIV155ZV67LHHNGrUKE2fPl233367li1b1lPzkyRVVFQoEAg4W3Nzc48+HgAAsENEITN48GDl5OSE7Rs+fLgOHDggSfJ6vZKklpaWsDEtLS3OMa/Xq9bW1rDjx48fV1tbmzPmmxITE+VyucI2AACAiEJmwoQJampqCtu3d+9eXXzxxZKk7Oxseb1e1dTUOMeDwaDq6+vl8/kkST6fT+3t7WpsbHTGbNiwQaFQSHl5eWf8RAAAQN8TH8ng2bNna/z48Xrsscf0i1/8Qps3b9bzzz+v559/XpIUExOjWbNm6Te/+Y2GDh2q7OxszZs3TxkZGZo8ebKk/57BmTRpkvMnqWPHjqmsrExTpkw5rU8sAQAAnBBRyIwZM0br1q1TRUWFHnnkEWVnZ+vpp59WcXGxM+a+++7TkSNHNH36dLW3t+uqq67S+vXr1b9/f2fMqlWrVFZWpokTJyo2NlZFRUVavHhx9z0rAADQJ0R0HZnzBdeRORnXkQEAnO+ifh0ZAACA8wkhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBahAwAALAWIQMAAKxFyAAAAGsRMgAAwFqEDAAAsBYhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBa8dGeALrHkPI3oz2FiH28sDDaUwAAWI4zMgAAwFqEDAAAsBYhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBahAwAALAWIQMAAKxFyAAAAGsRMgAAwFqEDAAAsBYhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBahAwAALAWIQMAAKxFyAAAAGsRMgAAwFqEDAAAsBYhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBahAwAALAWIQMAAKxFyAAAAGsRMgAAwFqEDAAAsBYhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBahAwAALAWIQMAAKx1ViGzcOFCxcTEaNasWc6+o0ePqrS0VGlpaRo0aJCKiorU0tISdrsDBw6osLBQAwYMUHp6uubOnavjx4+fzVQAAEAfdMYh09DQoD/84Q+67LLLwvbPnj1bb7zxhtauXava2lodPHhQN9xwg3O8q6tLhYWF6uzs1Pvvv6+VK1dqxYoVmj9//pk/CwAA0CedUcgcPnxYxcXFeuGFF3TBBRc4+wOBgF588UU9+eST+vGPf6zRo0dr+fLlev/997Vp0yZJ0l//+lft3r1bL730kq644gpdc801evTRR/Xss8+qs7Oze54VAADoE84oZEpLS1VYWKj8/Pyw/Y2NjTp27FjY/mHDhikrK0t1dXWSpLq6Oo0cOVIej8cZU1BQoGAwqF27dp3y8To6OhQMBsM2AACA+EhvsGbNGm3dulUNDQ0nHfP7/UpISFBKSkrYfo/HI7/f74z5esScOH7i2KlUVlbq4YcfjnSqAACgl4vojExzc7NmzpypVatWqX///j01p5NUVFQoEAg4W3Nz8zl7bAAAcP6KKGQaGxvV2tqqK6+8UvHx8YqPj1dtba0WL16s+Ph4eTwedXZ2qr29Pex2LS0t8nq9kiSv13vSp5hO/HxizDclJibK5XKFbQAAABGFzMSJE7Vjxw5t377d2XJzc1VcXOz8d79+/VRTU+PcpqmpSQcOHJDP55Mk+Xw+7dixQ62trc6Y6upquVwu5eTkdNPTAgAAfUFE75FJTk7WiBEjwvYNHDhQaWlpzv5p06Zpzpw5Sk1Nlcvl0l133SWfz6dx48ZJkq6++mrl5ORo6tSpWrRokfx+vx588EGVlpYqMTGxm54WAADoCyJ+s++3eeqppxQbG6uioiJ1dHSooKBAzz33nHM8Li5OVVVVmjFjhnw+nwYOHKiSkhI98sgj3T0VAADQy8UYY0y0JxGpYDAot9utQCDQI++XGVL+ZrffJ0728cLCaE8BAHAO9cTvb75rCQAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANYiZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANYiZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANaKj/YE0HcNKX8z2lOI2McLC6M9BQDA13BGBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANYiZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGAtQgYAAFiLkAEAANYiZAAAgLUIGQAAYC1CBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGCtiEKmsrJSY8aMUXJystLT0zV58mQ1NTWFjTl69KhKS0uVlpamQYMGqaioSC0tLWFjDhw4oMLCQg0YMEDp6emaO3eujh8/fvbPBgAA9CkRhUxtba1KS0u1adMmVVdX69ixY7r66qt15MgRZ8zs2bP1xhtvaO3ataqtrdXBgwd1ww03OMe7urpUWFiozs5Ovf/++1q5cqVWrFih+fPnd9+zAgAAfUKMMcac6Y0///xzpaenq7a2Vj/4wQ8UCAT0ne98R6tXr9bPf/5zSdKHH36o4cOHq66uTuPGjdNbb72l6667TgcPHpTH45EkLVu2TPfff78+//xzJSQkfOvjBoNBud1uBQIBuVyuM53+/2tI+Zvdfp/oHT5eWBjtKQCAtXri9/dZvUcmEAhIklJTUyVJjY2NOnbsmPLz850xw4YNU1ZWlurq6iRJdXV1GjlypBMxklRQUKBgMKhdu3adzXQAAEAfE3+mNwyFQpo1a5YmTJigESNGSJL8fr8SEhKUkpISNtbj8cjv9ztjvh4xJ46fOHYqHR0d6ujocH4OBoNnOm0AANCLnPEZmdLSUu3cuVNr1qzpzvmcUmVlpdxut7NlZmb2+GMCAIDz3xmFTFlZmaqqqvTOO+/ooosucvZ7vV51dnaqvb09bHxLS4u8Xq8z5pufYjrx84kx31RRUaFAIOBszc3NZzJtAADQy0QUMsYYlZWVad26ddqwYYOys7PDjo8ePVr9+vVTTU2Ns6+pqUkHDhyQz+eTJPl8Pu3YsUOtra3OmOrqarlcLuXk5JzycRMTE+VyucI2AACAiN4jU1paqtWrV+u1115TcnKy854Wt9utpKQkud1uTZs2TXPmzFFqaqpcLpfuuusu+Xw+jRs3TpJ09dVXKycnR1OnTtWiRYvk9/v14IMPqrS0VImJid3/DAEAQK8VUcgsXbpUkvSjH/0obP/y5ct1yy23SJKeeuopxcbGqqioSB0dHSooKNBzzz3njI2Li1NVVZVmzJghn8+ngQMHqqSkRI888sjZPRMAANDnnNV1ZKKF68ggWriODACcufPuOjIAAADRRMgAAABrETIAAMBahAwAALAWIQMAAKxFyAAAAGsRMgAAwFqEDAAAsBYhAwAArEXIAAAAaxEyAADAWhF9aSTQ19n4PVx8PxSA3owzMgAAwFqEDAAAsBYhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBahAwAALAWIQMAAKxFyAAAAGsRMgAAwFqEDAAAsBYhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBahAwAALAWIQMAAKxFyAAAAGsRMgAAwFqEDAAAsBYhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBahAwAALBWfLQnAKBnDSl/M9pTiNjHCwujPQUAluCMDAAAsBYhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACsRcgAAABrETIAAMBahAwAALAWIQMAAKxFyAAAAGsRMgAAwFp8aSSA8w5fdAngdHFGBgAAWIuQAQAA1iJkAACAtQgZAABgLUIGAABYi5ABAADWImQAAIC1CBkAAGCtqF4Q79lnn9UTTzwhv9+vyy+/XEuWLNHYsWOjOSUAOCNcxA+Ijqidkfnzn/+sOXPm6KGHHtLWrVt1+eWXq6CgQK2trdGaEgAAsEyMMcZE44Hz8vI0ZswYPfPMM5KkUCikzMxM3XXXXSovL/+ftw0Gg3K73QoEAnK5XN0+Nxv/nxUA9AWcRbJbT/z+jsqfljo7O9XY2KiKigpnX2xsrPLz81VXV3fS+I6ODnV0dDg/BwIBSf99QXpCqOPLHrlfAMDZyZq9NtpT6DN2PlzQ7fd54vd2d55DiUrIfPHFF+rq6pLH4wnb7/F49OGHH540vrKyUg8//PBJ+zMzM3tsjgAA9GXup3vuvg8dOiS3290t92XFt19XVFRozpw5zs+hUEhtbW1KS0tTTEzMSeODwaAyMzPV3NzcI396wrdjDaKPNYg+1iD6WIPo+/oaJCcn69ChQ8rIyOi2+49KyFx44YWKi4tTS0tL2P6WlhZ5vd6TxicmJioxMTFsX0pKyrc+jsvl4n+4UcYaRB9rEH2sQfSxBtF3Yg2660zMCVH51FJCQoJGjx6tmpoaZ18oFFJNTY18Pl80pgQAACwUtT8tzZkzRyUlJcrNzdXYsWP19NNP68iRI7r11lujNSUAAGCZqIXML3/5S33++eeaP3++/H6/rrjiCq1fv/6kNwCficTERD300EMn/TkK5w5rEH2sQfSxBtHHGkRfT69B1K4jAwAAcLb4riUAAGAtQgYAAFiLkAEAANYiZAAAgLV6Zcg8++yzGjJkiPr376+8vDxt3rw52lPqlSorKzVmzBglJycrPT1dkydPVlNTU9iYo0ePqrS0VGlpaRo0aJCKiopOuhAius/ChQsVExOjWbNmOftYg5736aef6uabb1ZaWpqSkpI0cuRIbdmyxTlujNH8+fM1ePBgJSUlKT8/X/v27YvijHuXrq4uzZs3T9nZ2UpKStIll1yiRx99NOz7fFiD7vXuu+/q+uuvV0ZGhmJiYvTqq6+GHT+d17utrU3FxcVyuVxKSUnRtGnTdPjw4cgnY3qZNWvWmISEBPPHP/7R7Nq1y9x+++0mJSXFtLS0RHtqvU5BQYFZvny52blzp9m+fbu59tprTVZWljl8+LAz5o477jCZmZmmpqbGbNmyxYwbN86MHz8+irPuvTZv3myGDBliLrvsMjNz5kxnP2vQs9ra2szFF19sbrnlFlNfX28++ugj8/bbb5t//vOfzpiFCxcat9ttXn31VfPBBx+Yn/zkJyY7O9t89dVXUZx577FgwQKTlpZmqqqqzP79+83atWvNoEGDzO9//3tnDGvQvf7yl7+YBx54wLzyyitGklm3bl3Y8dN5vSdNmmQuv/xys2nTJvPee++Z73//++amm26KeC69LmTGjh1rSktLnZ+7urpMRkaGqaysjOKs+obW1lYjydTW1hpjjGlvbzf9+vUza9eudcbs2bPHSDJ1dXXRmmavdOjQITN06FBTXV1tfvjDHzohwxr0vPvvv99cddVV/+/xUChkvF6veeKJJ5x97e3tJjEx0fzpT386F1Ps9QoLC81tt90Wtu+GG24wxcXFxhjWoKd9M2RO5/XevXu3kWQaGhqcMW+99ZaJiYkxn376aUSP36v+tNTZ2anGxkbl5+c7+2JjY5Wfn6+6uroozqxvCAQCkqTU1FRJUmNjo44dOxa2HsOGDVNWVhbr0c1KS0tVWFgY9lpLrMG58Prrrys3N1c33nij0tPTNWrUKL3wwgvO8f3798vv94etgdvtVl5eHmvQTcaPH6+amhrt3btXkvTBBx9o48aNuuaaaySxBufa6bzedXV1SklJUW5urjMmPz9fsbGxqq+vj+jxrPj269P1xRdfqKur66SrA3s8Hn344YdRmlXfEAqFNGvWLE2YMEEjRoyQJPn9fiUkJJz0BZ8ej0d+vz8Ks+yd1qxZo61bt6qhoeGkY6xBz/voo4+0dOlSzZkzR7/+9a/V0NCgu+++WwkJCSopKXFe51P9u8QadI/y8nIFg0ENGzZMcXFx6urq0oIFC1RcXCxJrME5djqvt9/vV3p6etjx+Ph4paamRrwmvSpkED2lpaXauXOnNm7cGO2p9CnNzc2aOXOmqqur1b9//2hPp08KhULKzc3VY489JkkaNWqUdu7cqWXLlqmkpCTKs+sbXn75Za1atUqrV6/WpZdequ3bt2vWrFnKyMhgDfqAXvWnpQsvvFBxcXEnfSKjpaVFXq83SrPq/crKylRVVaV33nlHF110kbPf6/Wqs7NT7e3tYeNZj+7T2Nio1tZWXXnllYqPj1d8fLxqa2u1ePFixcfHy+PxsAY9bPDgwcrJyQnbN3z4cB04cECSnNeZf5d6zty5c1VeXq4pU6Zo5MiRmjp1qmbPnq3KykpJrMG5djqvt9frVWtra9jx48ePq62tLeI16VUhk5CQoNGjR6umpsbZFwqFVFNTI5/PF8WZ9U7GGJWVlWndunXasGGDsrOzw46PHj1a/fr1C1uPpqYmHThwgPXoJhMnTtSOHTu0fft2Z8vNzVVxcbHz36xBz5owYcJJlx3Yu3evLr74YklSdna2vF5v2BoEg0HV19ezBt3kyy+/VGxs+K+zuLg4hUIhSazBuXY6r7fP51N7e7saGxudMRs2bFAoFFJeXl5kD3hWb1U+D61Zs8YkJiaaFStWmN27d5vp06eblJQU4/f7oz21XmfGjBnG7Xabv/3tb+azzz5zti+//NIZc8cdd5isrCyzYcMGs2XLFuPz+YzP54virHu/r39qyRjWoKdt3rzZxMfHmwULFph9+/aZVatWmQEDBpiXXnrJGbNw4UKTkpJiXnvtNfOPf/zD/PSnP+Wjv92opKTEfPe733U+fv3KK6+YCy+80Nx3333OGNagex06dMhs27bNbNu2zUgyTz75pNm2bZv517/+ZYw5vdd70qRJZtSoUaa+vt5s3LjRDB06lI9fn7BkyRKTlZVlEhISzNixY82mTZuiPaVeSdIpt+XLlztjvvrqK3PnnXeaCy64wAwYMMD87Gc/M5999ln0Jt0HfDNkWIOe98Ybb5gRI0aYxMREM2zYMPP888+HHQ+FQmbevHnG4/GYxMREM3HiRNPU1BSl2fY+wWDQzJw502RlZZn+/fub733ve+aBBx4wHR0dzhjWoHu98847p/z3v6SkxBhzeq/3v//9b3PTTTeZQYMGGZfLZW699VZz6NChiOcSY8zXLn0IAABgkV71HhkAANC3EDIAAMBahAwAALAWIQMAAKxFyAAAAGsRMgAAwFqEDAAAsBYhAwAArEXIAAAAaxEyAADAWoQMAACwFiEDAACs9X+xwrhM7E9ZNgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(id) for id in ids['input_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing inputs: 100%|██████████| 12544/12544 [00:12<00:00, 970.66it/s] \n"
     ]
    }
   ],
   "source": [
    "from model import Evolver\n",
    "from data import TrainLoader\n",
    "from train import train_evolver\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "evolver = Evolver(\n",
    "    d_model=512,\n",
    "    nhead=8,\n",
    "    max_len=64,\n",
    "    encoder_layers=6,\n",
    "    decoder_layers=6,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "optim = AdamW(evolver.parameters(), lr=3e-4)\n",
    "\n",
    "train_loader = TrainLoader.from_disk(\n",
    "    path='../data/ud/ud.jsonl',\n",
    "    bsz=128,\n",
    "    max_len=64,\n",
    "    tokenizer=BertTokenizer.from_pretrained('bert-base-cased')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:train:starting epoch: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5643, -1.5343, -1.5343], grad_fn=<SubBackward0>)\n",
      "tensor([-0.1877, -2.4584, -2.4584], grad_fn=<SubBackward0>)\n",
      "tensor([-2.1201, -0.8210, -0.8210], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-0.9040, -1.6601, -0.9040], grad_fn=<SubBackward0>)\n",
      "tensor([-0.9044, -1.6585, -0.9044], grad_fn=<SubBackward0>)\n",
      "tensor([-0.9015, -1.6709, -0.9015], grad_fn=<SubBackward0>)\n",
      "tensor([-0.9156, -1.6120, -0.9156], grad_fn=<SubBackward0>)\n",
      "tensor([-1.7024, -1.7024, -0.4533], grad_fn=<SubBackward0>)\n",
      "tensor([-1.5927, -1.5927, -0.5221], grad_fn=<SubBackward0>)\n",
      "tensor([-1.2527e+01, -1.2527e+01, -7.6294e-06], grad_fn=<SubBackward0>)\n",
      "tensor([-1.2440e+01, -1.2440e+01, -7.8678e-06], grad_fn=<SubBackward0>)\n",
      "tensor([-1.2398e+01, -1.2398e+01, -8.1062e-06], grad_fn=<SubBackward0>)\n",
      "tensor([-1.2297e+01, -1.2297e+01, -9.0599e-06], grad_fn=<SubBackward0>)\n",
      "tensor([-1.2387e+01, -1.2387e+01, -8.3447e-06], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.4434, -0.6391, -1.4435], grad_fn=<SubBackward0>)\n",
      "tensor([-0.6934, -8.3001, -0.6934], grad_fn=<SubBackward0>)\n",
      "tensor([-0.6934, -8.3062, -0.6934], grad_fn=<SubBackward0>)\n",
      "tensor([-0.6937, -7.3921, -0.6938], grad_fn=<SubBackward0>)\n",
      "tensor([-0.6946, -6.5583, -0.6946], grad_fn=<SubBackward0>)\n",
      "tensor([-0.2059, -4.8831, -1.7232], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0605, -3.4322, -3.6354], grad_fn=<SubBackward0>)\n",
      "tensor([-0.2232, -1.6860, -4.2164], grad_fn=<SubBackward0>)\n",
      "tensor([-4.1052, -0.0170, -7.9652], grad_fn=<SubBackward0>)\n",
      "tensor([ -3.1442,  -0.0441, -15.8769], grad_fn=<SubBackward0>)\n",
      "tensor([-5.0770e+00, -6.2561e-03, -1.5970e+01], grad_fn=<SubBackward0>)\n",
      "tensor([-4.7463e+00, -8.7204e-03, -1.6508e+01], grad_fn=<SubBackward0>)\n",
      "tensor([-7.2528e+00, -7.0953e-04, -1.4243e+01], grad_fn=<SubBackward0>)\n",
      "tensor([-9.6034e+00, -6.1035e-05, -1.3598e+01], grad_fn=<SubBackward0>)\n",
      "tensor([-12.0043,   0.0000, -14.1042], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0855, -0.9481, -1.2918], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0617, -1.4290, -0.8805], grad_fn=<SubBackward0>)\n",
      "tensor([-2.8244, -0.1854, -2.2085], grad_fn=<SubBackward0>)\n",
      "tensor([ -1.0674, -14.4589,  -0.4214], grad_fn=<SubBackward0>)\n",
      "tensor([ -0.4383, -14.9895,  -1.0360], grad_fn=<SubBackward0>)\n",
      "tensor([ -1.7576, -15.1215,  -0.1893], grad_fn=<SubBackward0>)\n",
      "tensor([ -2.0366, -14.4903,  -0.1398], grad_fn=<SubBackward0>)\n",
      "tensor([ -3.3953, -13.7626,  -0.0341], grad_fn=<SubBackward0>)\n",
      "tensor([ -3.3385, -12.8609,  -0.0361], grad_fn=<SubBackward0>)\n",
      "tensor([-4.6916e+00, -1.1704e+01, -9.2239e-03], grad_fn=<SubBackward0>)\n",
      "tensor([-4.9478e+00, -1.0754e+01, -7.1487e-03], grad_fn=<SubBackward0>)\n",
      "tensor([-6.3664e+00, -1.1223e+01, -1.7319e-03], grad_fn=<SubBackward0>)\n",
      "tensor([-1.4662, -5.3260, -0.2687], grad_fn=<SubBackward0>)\n",
      "tensor([-1.6287, -4.4814, -0.2326], grad_fn=<SubBackward0>)\n",
      "tensor([-5.5366, -2.9404, -0.0585], grad_fn=<SubBackward0>)\n",
      "tensor([-5.4392, -2.1442, -0.1295], grad_fn=<SubBackward0>)\n",
      "tensor([-4.2513, -2.8309, -0.0760], grad_fn=<SubBackward0>)\n",
      "tensor([-4.1213, -3.0406, -0.0662], grad_fn=<SubBackward0>)\n",
      "tensor([-1.1413e+01, -6.8073e+00, -1.1139e-03], grad_fn=<SubBackward0>)\n",
      "tensor([-1.2918e+01, -7.7684e+00, -4.2725e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-1.5866e+01, -9.5116e+00, -7.6294e-05], grad_fn=<SubBackward0>)\n",
      "tensor([-1.5369e+01, -8.2221e+00, -2.6703e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-1.6614e+01, -9.4150e+00, -8.3923e-05], grad_fn=<SubBackward0>)\n",
      "tensor([-1.6581e+01, -8.8869e+00, -1.3733e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-1.7067e+01, -8.1573e+00, -2.8992e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-1.7160e+01, -8.4123e+00, -2.2125e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-1.7839e+01, -8.5247e+00, -1.9836e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-1.8505e+01, -8.0214e+00, -3.3569e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-1.9568e+01, -8.0143e+00, -3.2806e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-1.9069e+01, -8.8252e+00, -1.5259e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-3.7826e+01, -9.2600e+00, -9.1553e-05], grad_fn=<SubBackward0>)\n",
      "tensor([-3.8303e+01, -8.8773e+00, -1.3733e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-37.7873,  -3.0753,  -0.0473], grad_fn=<SubBackward0>)\n",
      "tensor([-4.2485e+01, -4.1827e+00, -1.5373e-02], grad_fn=<SubBackward0>)\n",
      "tensor([-4.3187e+01, -4.4394e+00, -1.1871e-02], grad_fn=<SubBackward0>)\n",
      "tensor([-4.2390e+01, -3.7479e+00, -2.3849e-02], grad_fn=<SubBackward0>)\n",
      "tensor([-4.4064e+01, -4.0367e+00, -1.7807e-02], grad_fn=<SubBackward0>)\n",
      "tensor([-4.6051e+01, -4.1628e+00, -1.5686e-02], grad_fn=<SubBackward0>)\n",
      "tensor([-6.6025e+01, -3.1080e+00, -4.5723e-02], grad_fn=<SubBackward0>)\n",
      "tensor([-63.8788,  -1.6509,  -0.2130], grad_fn=<SubBackward0>)\n",
      "tensor([-63.8401,  -1.6664,  -0.2094], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-0.7912, -1.2970, -1.2970], grad_fn=<SubBackward0>)\n",
      "tensor([-0.7173, -1.6637, -1.1317], grad_fn=<SubBackward0>)\n",
      "tensor([-5.1537, -0.0100, -5.4876], grad_fn=<SubBackward0>)\n",
      "tensor([-4.5853e-03, -5.4267e+00, -8.6192e+00], grad_fn=<SubBackward0>)\n",
      "tensor([  0.0000, -12.9805, -14.5764], grad_fn=<SubBackward0>)\n",
      "tensor([-4.5007, -0.0173, -5.1025], grad_fn=<SubBackward0>)\n",
      "tensor([-1.1327, -0.4136, -4.0995], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0731, -2.6629, -7.1944], grad_fn=<SubBackward0>)\n",
      "tensor([-1.6174e-03, -7.0250e+00, -7.2267e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-5.1117e-04, -7.6698e+00, -1.0007e+01], grad_fn=<SubBackward0>)\n",
      "tensor([-6.6376e-04, -7.3239e+00, -1.3349e+01], grad_fn=<SubBackward0>)\n",
      "tensor([-4.2953e-03, -5.4529e+00, -1.2040e+01], grad_fn=<SubBackward0>)\n",
      "tensor([-3.0518e-05, -1.0347e+01, -1.5368e+01], grad_fn=<SubBackward0>)\n",
      "tensor([-2.2507e-03, -6.1514e+00, -9.0724e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-5.0354e-03, -5.4612e+00, -7.1658e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-5.2433e-03, -5.4262e+00, -7.0943e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-0.7172, -1.3628, -1.3628], grad_fn=<SubBackward0>)\n",
      "tensor([-8.1641, -0.6934, -0.6934], grad_fn=<SubBackward0>)\n",
      "tensor([-8.4754, -0.6934, -0.6934], grad_fn=<SubBackward0>)\n",
      "tensor([-14.8353,  -0.6931,  -0.6932], grad_fn=<SubBackward0>)\n",
      "tensor([-17.3529,  -1.3525,  -0.2992], grad_fn=<SubBackward0>)\n",
      "tensor([-1.5535e+01, -1.3924e-02, -4.2811e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-1.6758e+01, -8.6975e-04, -7.0514e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-1.8764e+01, -8.3923e-05, -9.3923e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-1.8804e+01, -7.7724e-05, -9.4604e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.4253, -1.4253, -0.6556], grad_fn=<SubBackward0>)\n",
      "tensor([-2.2777, -2.2777, -0.2295], grad_fn=<SubBackward0>)\n",
      "tensor([-1.8974, -2.7274, -0.2425], grad_fn=<SubBackward0>)\n",
      "tensor([-4.0817e-03, -9.0721e+00, -5.5316e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-4.5776e-04, -9.9358e+00, -7.8034e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.7629, -1.7629, -0.4202], grad_fn=<SubBackward0>)\n",
      "tensor([-1.7877, -1.7876, -0.4075], grad_fn=<SubBackward0>)\n",
      "tensor([-1.7571, -1.7570, -0.4233], grad_fn=<SubBackward0>)\n",
      "tensor([-1.7301, -1.7301, -0.4378], grad_fn=<SubBackward0>)\n",
      "tensor([-1.6979, -1.6978, -0.4560], grad_fn=<SubBackward0>)\n",
      "tensor([-0.5175, -1.5995, -1.5995], grad_fn=<SubBackward0>)\n",
      "tensor([-0.4779, -1.6609, -1.6609], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0314, -4.1688, -4.1688], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0333, -4.1124, -4.1124], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0342, -4.0863, -4.0863], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0366, -4.0194, -4.0194], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0153, -4.8796, -4.8797], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0146, -4.9256, -4.9256], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0189, -4.9364, -4.4651], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0186, -4.9557, -4.4761], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0180, -4.9877, -4.5081], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.0986, -1.0986, -1.0986], grad_fn=<SubBackward0>)\n",
      "tensor([-1.8922, -1.8923, -0.3588], grad_fn=<SubBackward0>)\n",
      "tensor([-2.0023, -1.8693, -0.3414], grad_fn=<SubBackward0>)\n",
      "tensor([-2.0432, -1.8964, -0.3281], grad_fn=<SubBackward0>)\n",
      "tensor([-2.3521, -3.2191, -0.1452], grad_fn=<SubBackward0>)\n",
      "tensor([-1.8404, -2.5463, -0.2707], grad_fn=<SubBackward0>)\n",
      "tensor([-2.4506, -3.6108, -0.1202], grad_fn=<SubBackward0>)\n",
      "tensor([-2.4588, -3.6298, -0.1188], grad_fn=<SubBackward0>)\n",
      "tensor([-3.2657, -5.6451, -0.0426], grad_fn=<SubBackward0>)\n",
      "tensor([-2.3782, -5.3768, -0.1024], grad_fn=<SubBackward0>)\n",
      "tensor([-1.5027, -4.7370, -0.2630], grad_fn=<SubBackward0>)\n",
      "tensor([-3.5717, -6.4484, -0.0301], grad_fn=<SubBackward0>)\n",
      "tensor([-2.9645, -5.7532, -0.0563], grad_fn=<SubBackward0>)\n",
      "tensor([-4.2255, -7.6364, -0.0152], grad_fn=<SubBackward0>)\n",
      "tensor([-5.8123e+00, -9.5822e+00, -3.0670e-03], grad_fn=<SubBackward0>)\n",
      "tensor([-4.6778, -8.3611, -0.0096], grad_fn=<SubBackward0>)\n",
      "tensor([-3.7854, -7.7487, -0.0234], grad_fn=<SubBackward0>)\n",
      "tensor([-2.3329, -6.7697, -0.1033], grad_fn=<SubBackward0>)\n",
      "tensor([-2.5366, -6.6915, -0.0838], grad_fn=<SubBackward0>)\n",
      "tensor([-3.7806, -7.9599, -0.0234], grad_fn=<SubBackward0>)\n",
      "tensor([-3.4237, -7.2358, -0.0339], grad_fn=<SubBackward0>)\n",
      "tensor([-4.8935e+00, -9.0306e+00, -7.6447e-03], grad_fn=<SubBackward0>)\n",
      "tensor([-2.9382, -8.7034, -0.0546], grad_fn=<SubBackward0>)\n",
      "tensor([-5.8857e+00, -1.5472e+01, -2.7847e-03], grad_fn=<SubBackward0>)\n",
      "tensor([-5.8013e+00, -1.5212e+01, -3.0289e-03], grad_fn=<SubBackward0>)\n",
      "tensor([-4.8156e+00, -1.4037e+01, -8.1329e-03], grad_fn=<SubBackward0>)\n",
      "tensor([ -3.3557, -13.2930,  -0.0355], grad_fn=<SubBackward0>)\n",
      "tensor([-7.2883e+00, -6.0706e+00, -2.9984e-03], grad_fn=<SubBackward0>)\n",
      "tensor([-6.1618, -4.7698, -0.0107], grad_fn=<SubBackward0>)\n",
      "tensor([-5.6391, -5.2810, -0.0087], grad_fn=<SubBackward0>)\n",
      "tensor([-1.2789e+01, -3.3417e-03, -5.7036e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-2.0982e+01, -8.3018e+00, -2.4796e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-2.1094e+01, -8.4208e+00, -2.2030e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-2.0510e+01, -7.2496e+00, -7.0953e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-2.2379e+01, -1.0225e+01, -3.8147e-05], grad_fn=<SubBackward0>)\n",
      "tensor([-2.2407e+01, -1.0269e+01, -3.4571e-05], grad_fn=<SubBackward0>)\n",
      "tensor([-2.1505e+01, -8.7231e+00, -1.6022e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-2.1411e+01, -8.3273e+00, -2.4414e-04], grad_fn=<SubBackward0>)\n",
      "tensor([-2.3974e+01, -1.2097e+01, -7.6294e-06], grad_fn=<SubBackward0>)\n",
      "tensor([-2.2440e+01, -1.1258e+01, -1.5259e-05], grad_fn=<SubBackward0>)\n",
      "tensor([-24.9815, -12.9645,   0.0000], grad_fn=<SubBackward0>)\n",
      "tensor([-0.4414, -1.6693, -1.7810], grad_fn=<SubBackward0>)\n",
      "tensor([-5.7220e-04, -8.0367e+00, -8.3069e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-8.5449e-04, -8.0792e+00, -7.5109e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-5.7220e-03, -8.8214e+00, -5.1922e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-4.2267e-03, -8.4359e+00, -5.5219e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-3.9139e-03, -8.3341e+00, -5.6094e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-6.9809e-03, -8.3896e+00, -5.0017e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-6.9809e-03, -8.4062e+00, -5.0007e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0189, -8.0443, -3.9948], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0101, -7.4611, -4.6624], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0098, -5.5206, -5.1613], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0178, -6.1179, -4.1720], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0159, -6.2257, -4.2860], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0299, -6.2916, -3.5884], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0415, -4.8203, -3.4245], grad_fn=<SubBackward0>)\n",
      "tensor([-0.2046, -5.2623, -1.7157], grad_fn=<SubBackward0>)\n",
      "tensor([-0.0334, -6.9738, -3.4440], grad_fn=<SubBackward0>)\n",
      "tensor([-8.2397e-04, -1.6911e+01, -7.1007e+00], grad_fn=<SubBackward0>)\n",
      "tensor([-2.5940e-03, -1.7335e+01, -5.9572e+00], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_evolver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_accum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_at\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_at\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_particles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mud-cpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/argo/projects/ddm/evolver/cookbooks/../train.py:90\u001b[0m, in \u001b[0;36mtrain_evolver\u001b[0;34m(evolver, optim, train_loader, eval_loader, epochs, grad_accum_steps, checkpoint_at, eval_at, num_particles, threshold, temperature, device, prefix)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     86\u001b[0m     \n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# E-step\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     evolver\u001b[38;5;241m.\u001b[39meval() \n\u001b[1;32m     89\u001b[0m     traj_input_ids, traj_edit_tgts \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 90\u001b[0m         \u001b[43msample_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_particles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# M-step\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     evolver\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/argo/projects/ddm/evolver/cookbooks/../run.py:39\u001b[0m, in \u001b[0;36msample_batch\u001b[0;34m(evolver, batch_ids, num_particles, threshold, temperature, device)\u001b[0m\n\u001b[1;32m     36\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m batch_ids)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m batch_ids:\n\u001b[0;32m---> 39\u001b[0m     cur_tgts, _ \u001b[38;5;241m=\u001b[39m \u001b[43msample_trajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_particles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m pad_traj_input_ids(input_ids, T)\n\u001b[1;32m     46\u001b[0m     cur_tgts \u001b[38;5;241m=\u001b[39m pad_traj_edit_tgts(cur_tgts, T\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/argo/projects/ddm/evolver/cookbooks/../run.py:70\u001b[0m, in \u001b[0;36msample_trajectory\u001b[0;34m(evolver, traj_input_ids, num_particles, threshold, temperature, device)\u001b[0m\n\u001b[1;32m     67\u001b[0m traj_edit_tgts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 70\u001b[0m     edit_tgts, src, log_prob \u001b[38;5;241m=\u001b[39m \u001b[43mparticle_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_input_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_input_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_pad_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraj_pad_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_particles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# ugly, but we short-circuit the particle filter after EOS so we need this input to be padded again\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     src \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([src, torch\u001b[38;5;241m.\u001b[39mzeros(src\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], evolver\u001b[38;5;241m.\u001b[39mmax_len\u001b[38;5;241m-\u001b[39msrc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], evolver\u001b[38;5;241m.\u001b[39md_model)\u001b[38;5;241m.\u001b[39mto(device)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/argo/projects/ddm/evolver/cookbooks/../run.py:108\u001b[0m, in \u001b[0;36mparticle_filter\u001b[0;34m(evolver, input_ids, output_ids, src, src_pad_mask, tgt_pad_mask, M, threshold, temperature, device)\u001b[0m\n\u001b[1;32m    105\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, forced \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(output_ids[\u001b[38;5;241m1\u001b[39m:], start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# forward pass \u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     edit_logits, tgt, memory, cache \u001b[38;5;241m=\u001b[39m \u001b[43mevolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_pad_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_pad_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# get logits \u001b[39;00m\n\u001b[1;32m    116\u001b[0m     op_probs, tok_probs, idx_probs \u001b[38;5;241m=\u001b[39m evolver\u001b[38;5;241m.\u001b[39mget_probs(edit_logits, src_pad_mask)\n",
      "File \u001b[0;32m~/argo/projects/ddm/evolver/cookbooks/../model.py:282\u001b[0m, in \u001b[0;36mEvolver.forward\u001b[0;34m(self, input_ids, src, edit_tgts, src_pad_mask, tgt_pad_mask, memory, cache)\u001b[0m\n\u001b[1;32m    274\u001b[0m output, new_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[1;32m    275\u001b[0m     tgt, memory,\n\u001b[1;32m    276\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m    277\u001b[0m     tgt_key_padding_mask\u001b[38;5;241m=\u001b[39mtgt_pad_mask[:, :cur_len],\n\u001b[1;32m    278\u001b[0m     memory_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_pad_mask,\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    281\u001b[0m op_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop_head(output)\n\u001b[0;32m--> 282\u001b[0m tok_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtok_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m idx_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx_head(output)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    286\u001b[0m     (op_logits, tok_logits, idx_logits),\n\u001b[1;32m    287\u001b[0m     tgt, memory, new_cache\n\u001b[1;32m    288\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/evo/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/evo/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/evo/lib/python3.8/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_evolver(\n",
    "    evolver, optim, train_loader, None,\n",
    "    epochs=1,\n",
    "    grad_accum_steps=1,\n",
    "    checkpoint_at=1,\n",
    "    eval_at=1e10,\n",
    "    num_particles=3,\n",
    "    threshold=1,\n",
    "    temperature=0.7,\n",
    "    device='cpu',\n",
    "    prefix='ud-cpu'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
